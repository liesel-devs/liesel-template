---
title: "liesel-template: GNU Parallel example: Scenario"
format: gfm
params:
  job: 42
---

This small simulation study builds on the Quarto example (the semi-parametric distributional regression model with the bivariate normal response variable) but uses a parameterized Quarto document to generate data with different PRNG seeds. GNU Parallel passes the job number to Quarto as a parameter, which is then used to set the PRNG seed before generating the data. Finally, the results are stored in an RDS file for each job.

```{r}
#| include: false

library(ggplot2)
library(MASS)
library(reticulate)
library(rliesel)
```

```{python}
#| include: false

import numpy as np
import pandas as pd

import liesel.model as lsl
import liesel.goose as gs

from liesel_template import BivariateNormal

gs.Summary.__repr__ = gs.Summary._repr_html_
gs.Summary._repr_markdown_ = gs.Summary._repr_html_
pd.options.display.float_format = "{:.3f}".format
pd.options.display.html.border = 0
```

## Generate some data

Generate five covariates with non-linear effects on the marginal means and linear effects on the marginal standard deviations and the correlation parameter of a bivariate normal response variable.

```{r}
set.seed(params$job)

n <- 1000

x1 <- runif(n)
x2 <- runif(n)
x3 <- runif(n)
x4 <- runif(n)
x5 <- runif(n)

y <- vapply(1:n, function(i) {
  loc1 <- sin(2 * pi * x1[i])
  loc2 <- cos(2 * pi * x2[i])
  scale1 <- exp(x3[i])
  scale2 <- exp(x4[i])
  cor <- tanh(x5[i])

  mu <- c(loc1, loc2)
  cov <- scale1 * scale2 * cor
  sigma <- matrix(c(scale1^2, cov, cov, scale2^2), nrow = 2)
  mvrnorm(1, mu, sigma)
}, FUN.VALUE = c(0, 0))

y <- t(y)
```

## Configure semi-parametric distributional regression model

Configure the correct data-generating model using RLiesel.

```{r}
model <- liesel(
  response = y,
  distribution = py$BivariateNormal,
  predictors = list(
    loc1 = predictor(~s(x1), inverse_link = "Identity"),
    loc2 = predictor(~s(x2), inverse_link = "Identity"),
    scale1 = predictor(~x3, inverse_link = "Exp"),
    scale2 = predictor(~x4, inverse_link = "Exp"),
    cor = predictor(~x5, inverse_link = "Tanh")
  )
)
```

## Run MCMC sampler

This MCMC sampler uses IWLS kernels for the regression coefficients and Gibbs kernels for the smoothing parameters.

```{python}
builder = lsl.dist_reg_mcmc(r.model, seed=1337, num_chains=4)
builder.set_duration(warmup_duration=1000, posterior_duration=1000)

engine = builder.build()
engine.sample_all_epochs()

results = engine.get_results()
summary = gs.Summary(results)
```

```{python}
summary
```

## Visualize estimated splines

Compute estimated functions in Python...

```{python}
x = r.model.vars["loc1_np0_X"].value
beta = summary.quantities["mean"]["loc1_np0_beta"]
loc1_hat = np.asarray(x @ beta)

x = r.model.vars["loc2_np0_X"].value
beta = summary.quantities["mean"]["loc2_np0_beta"]
loc2_hat = np.asarray(x @ beta)
```

... and store them in an RDS file.

```{r}
df <- data.frame(
  x = c(x1, x2),
  f = c(py$loc1_hat, py$loc2_hat),
  param = rep(c("loc1", "loc2"), each = n),
  job = params$job
)

saveRDS(df, "splines.rds")
```
